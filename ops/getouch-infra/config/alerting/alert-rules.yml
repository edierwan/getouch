# ============================================================================
# Prometheus Alert Rules for Getouch Infrastructure
# ============================================================================
# Deploy to: /opt/getouch/monitoring/alert-rules.yml
# Referenced by prometheus.yml via rule_files directive.
# ============================================================================

groups:
  # ── Host Alerts ───────────────────────────────────────────────────

  - name: host_alerts
    rules:
      - alert: HighCpuUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 85% for more than 10 minutes. Current: {{ $value | printf \"%.1f\" }}%"

      - alert: CriticalCpuUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Critical CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 95% for 5 minutes. Current: {{ $value | printf \"%.1f\" }}%"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85%. Current: {{ $value | printf \"%.1f\" }}%"

      - alert: CriticalMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Critical memory usage on {{ $labels.instance }}"
          description: "Memory usage above 95%. Current: {{ $value | printf \"%.1f\" }}%"

      - alert: DiskSpaceWarning
        expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"})) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Disk space running low on {{ $labels.instance }}"
          description: "{{ $labels.mountpoint }} is {{ $value | printf \"%.1f\" }}% full"

      - alert: DiskSpaceCritical
        expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"})) * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Disk space critical on {{ $labels.instance }}"
          description: "{{ $labels.mountpoint }} is {{ $value | printf \"%.1f\" }}% full. Immediate action required!"

      - alert: HighDiskIO
        expr: rate(node_disk_io_time_seconds_total[5m]) > 0.9
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "High disk I/O on {{ $labels.instance }}"
          description: "Disk {{ $labels.device }} is under heavy I/O for 15+ minutes"

  # ── Docker / Container Alerts ─────────────────────────────────────

  - name: container_alerts
    rules:
      - alert: ContainerDown
        expr: absent(container_last_seen{name=~"caddy|getouch-api|getouch-bot|getouch-landing|wa-gateway|postgres|cloudflared"}) == 1
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Container {{ $labels.name }} appears to be down"
          description: "Container {{ $labels.name }} has not reported metrics for 2+ minutes"

      - alert: ContainerHighCpu
        expr: rate(container_cpu_usage_seconds_total{name!=""}[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.name }} high CPU"
          description: "Container {{ $labels.name }} CPU usage above 80% for 10 minutes: {{ $value | printf \"%.1f\" }}%"

      - alert: ContainerHighMemory
        expr: container_memory_usage_bytes{name!=""} / container_spec_memory_limit_bytes{name!=""} * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.name }} high memory"
          description: "Container {{ $labels.name }} using {{ $value | printf \"%.1f\" }}% of memory limit"

      - alert: ContainerRestarting
        expr: increase(container_restarts_total{name!=""}[1h]) > 3
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.name }} restarting frequently"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last hour"

  # ── Network / Connectivity Alerts ─────────────────────────────────

  - name: network_alerts
    rules:
      - alert: HighNetworkTraffic
        expr: rate(node_network_receive_bytes_total{device!~"lo|tailscale.*|docker.*|veth.*|br-.*"}[5m]) > 50e6
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High inbound network traffic on {{ $labels.instance }}"
          description: "Receiving > 50MB/s on {{ $labels.device }} for 10+ minutes"

      - alert: NodeExporterDown
        expr: up{job="node-exporter"} == 0
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "Node exporter is down"
          description: "Prometheus cannot scrape node-exporter for 3+ minutes"

  # ── Prometheus Self-Monitoring ────────────────────────────────────

  - name: prometheus_alerts
    rules:
      - alert: PrometheusTargetDown
        expr: up == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Prometheus target {{ $labels.job }} is down"
          description: "Target {{ $labels.instance }} in job {{ $labels.job }} is unreachable for 5+ minutes"

      - alert: PrometheusRuleEvaluationFailures
        expr: increase(prometheus_rule_evaluation_failures_total[5m]) > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Prometheus rule evaluation failures"
          description: "Rule group {{ $labels.rule_group }} has evaluation failures"
